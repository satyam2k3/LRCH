{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11222741,"sourceType":"datasetVersion","datasetId":7008902},{"sourceId":11359789,"sourceType":"datasetVersion","datasetId":7109777}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndef prepare_medical_data(csv_file, test_size=0.2, random_state=42):\n    df = pd.read_csv(csv_file)\n    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True) \n\n    # DATASET LABELING\n    df[\"label\"] = df[\"med_field\"].astype(\"category\").cat.codes\n    label2id = dict(enumerate(df[\"med_field\"].astype(\"category\").cat.categories))\n    id2label = {v: k for k, v in label2id.items()}\n    num_labels = len(id2label) \n    \n    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n    \n    train_df = train_df.reset_index(drop=True)\n    test_df = test_df.reset_index(drop=True)\n    \n    return train_df, test_df, label2id, id2label, num_labels\n\n# PROVIDING .CSV CONTAINING COMPILATION OF ALL THE MEDICAL FIELD CONTAINING 30K QUESTION-ANSWER PAIR \ntrain_df, test_df, label2id, id2label, num_labels = prepare_medical_data(\"/kaggle/input/dataset-new/preprocessed_medical_qa (2).csv\")","metadata":{"_uuid":"2c9feb69-4790-4f4c-a835-e21f416d3f71","_cell_guid":"a2455709-7c52-4cfa-bbb3-15a3c3cd2a58","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T19:34:49.485782Z","iopub.execute_input":"2025-04-17T19:34:49.486021Z","iopub.status.idle":"2025-04-17T19:34:52.650885Z","shell.execute_reply.started":"2025-04-17T19:34:49.485998Z","shell.execute_reply":"2025-04-17T19:34:52.649961Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"print(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:34:52.651931Z","iopub.execute_input":"2025-04-17T19:34:52.652547Z","iopub.status.idle":"2025-04-17T19:34:52.657272Z","shell.execute_reply.started":"2025-04-17T19:34:52.652511Z","shell.execute_reply":"2025-04-17T19:34:52.656401Z"}},"outputs":[{"name":"stdout","text":"{0: 'Alergist', 1: 'Cardiologist', 2: 'Dermatologist', 3: 'Endocrinologist', 4: 'Gastroenterologist', 5: 'Genetics', 6: 'Geriatrics', 7: 'Neurologist', 8: 'Oncologist/Hematologist', 9: 'Orthopedics', 10: 'OtherQA'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(id2label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:34:52.658074Z","iopub.execute_input":"2025-04-17T19:34:52.658303Z","iopub.status.idle":"2025-04-17T19:34:52.678951Z","shell.execute_reply.started":"2025-04-17T19:34:52.658285Z","shell.execute_reply":"2025-04-17T19:34:52.678131Z"}},"outputs":[{"name":"stdout","text":"{'Alergist': 0, 'Cardiologist': 1, 'Dermatologist': 2, 'Endocrinologist': 3, 'Gastroenterologist': 4, 'Genetics': 5, 'Geriatrics': 6, 'Neurologist': 7, 'Oncologist/Hematologist': 8, 'Orthopedics': 9, 'OtherQA': 10}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import Dataset\n\n\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)","metadata":{"_uuid":"3a83efa5-635c-40a8-9a52-16b050b2f96f","_cell_guid":"1b2f41f6-e938-4b59-94f4-61e5f32b938e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T19:34:52.680840Z","iopub.execute_input":"2025-04-17T19:34:52.681116Z","iopub.status.idle":"2025-04-17T19:34:54.650016Z","shell.execute_reply.started":"2025-04-17T19:34:52.681080Z","shell.execute_reply":"2025-04-17T19:34:54.649134Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast \n\nmodel_name = \"distilbert-base-uncased\" \ntokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n\nmax_length = 256\n\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"], \n        padding=\"max_length\", \n        truncation=True, \n        max_length=max_length\n    )\n\ntrain_dataset = train_dataset.map(tokenize_function, batched=True)\ntest_dataset = test_dataset.map(tokenize_function, batched=True)\n\ntrain_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"_uuid":"bae6e6e0-02dc-4b88-9927-9dec05a158d1","_cell_guid":"a02cf2ff-0db5-4a2a-b1eb-716983cc4849","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T19:34:54.651292Z","iopub.execute_input":"2025-04-17T19:34:54.651699Z","iopub.status.idle":"2025-04-17T19:35:14.548668Z","shell.execute_reply.started":"2025-04-17T19:34:54.651677Z","shell.execute_reply":"2025-04-17T19:35:14.547568Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3189333645e4f82bdf07557c9c94495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d817964b30b241b1a71624c01ef3dbd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f360b74a5a3047f4a875efef693548e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ada8a1b1674805acbc7276971b8804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20589 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"770e24d2b1ed49a78b322fad39c43adb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5148 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"235c7ed9ab124b1ba54848bfbca1b025"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification\n\nmodel = DistilBertForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=num_labels,\n    id2label=id2label, \n    label2id={label: id_ for id_, label in id2label.items()} \n)","metadata":{"_uuid":"1a56838e-1e1b-4f14-99ca-05b14795889d","_cell_guid":"c7c39c85-e754-42f3-a85d-6cdee551dc98","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T19:35:14.549598Z","iopub.execute_input":"2025-04-17T19:35:14.549902Z","iopub.status.idle":"2025-04-17T19:35:30.184300Z","shell.execute_reply.started":"2025-04-17T19:35:14.549877Z","shell.execute_reply":"2025-04-17T19:35:30.183677Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84074e5fcc3e4080bfc0fd4b2c45c544"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import logging\n!pip install evaluate","metadata":{"_uuid":"ae116348-8e1f-4602-bbd3-16e6d12b2779","_cell_guid":"80d46deb-92b9-4672-b62b-dba85660390a","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:35:30.185114Z","iopub.execute_input":"2025-04-17T19:35:30.185636Z","iopub.status.idle":"2025-04-17T19:35:35.308973Z","shell.execute_reply.started":"2025-04-17T19:35:30.185612Z","shell.execute_reply":"2025-04-17T19:35:35.308119Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nfrom transformers import TrainingArguments, Trainer, TrainerCallback\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"Using GPU:\", torch.cuda.get_device_name(device))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"Using CPU\")\n\nmodel = model.to(device)\nprint(\"Model device:\", next(model.parameters()).device)  \n\n# Your existing imports and code for TrainingArguments, Trainer, etc.\n\nbatch_size = 8\nlogging_steps = 100\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results_distilbert\",\n    eval_strategy=\"epoch\",  \n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=6,  \n    logging_steps=logging_steps,\n    save_strategy=\"epoch\",  \n    load_best_model_at_end=True,\n    save_total_limit=1,\n    disable_tqdm= True,         \n    report_to=[\"none\"],\n)\n\nclass PrintCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            print(f\"Step: {state.global_step} | Logs: {logs}\", flush=True)\n\n    def on_epoch_end(self, args, state, control, **kwargs):\n        if state.log_history:\n            print(f\"Epoch {state.epoch} ended. Latest log: {state.log_history[-1]}\", flush=True)\n\ndef compute_metrics(eval_preds):\n    import numpy as np\n    import evaluate  \n    \n    accuracy_metric = evaluate.load(\"accuracy\")\n    precision_metric = evaluate.load(\"precision\")\n    recall_metric = evaluate.load(\"recall\")\n    f1_metric = evaluate.load(\"f1\")\n    \n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=1)\n    \n    accuracy_result = accuracy_metric.compute(predictions=predictions, references=labels)\n    precision_result = precision_metric.compute(predictions=predictions, references=labels, average='macro')\n    recall_result = recall_metric.compute(predictions=predictions, references=labels, average='macro')\n    f1_result = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n    \n    return {\n        \"accuracy\": accuracy_result[\"accuracy\"],\n        \"precision\": precision_result[\"precision\"],\n        \"recall\": recall_result[\"recall\"],\n        \"f1\": f1_result[\"f1\"],\n    }\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[PrintCallback]\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T19:35:35.310020Z","iopub.execute_input":"2025-04-17T19:35:35.310302Z","iopub.status.idle":"2025-04-17T20:09:12.134480Z","shell.execute_reply.started":"2025-04-17T19:35:35.310277Z","shell.execute_reply":"2025-04-17T20:09:12.133651Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Using GPU: Tesla T4\nModel device: cuda:0\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-8-91878c647d80>:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 100 | Logs: {'loss': 1.5529, 'grad_norm': 5.017885208129883, 'learning_rate': 4.935249935249936e-05, 'epoch': 0.0777000777000777}\n{'loss': 1.5529, 'grad_norm': 5.017885208129883, 'learning_rate': 4.935249935249936e-05, 'epoch': 0.0777000777000777}\nStep: 200 | Logs: {'loss': 0.8407, 'grad_norm': 6.759465217590332, 'learning_rate': 4.8704998704998705e-05, 'epoch': 0.1554001554001554}\n{'loss': 0.8407, 'grad_norm': 6.759465217590332, 'learning_rate': 4.8704998704998705e-05, 'epoch': 0.1554001554001554}\nStep: 300 | Logs: {'loss': 0.5337, 'grad_norm': 5.941342830657959, 'learning_rate': 4.805749805749806e-05, 'epoch': 0.2331002331002331}\n{'loss': 0.5337, 'grad_norm': 5.941342830657959, 'learning_rate': 4.805749805749806e-05, 'epoch': 0.2331002331002331}\nStep: 400 | Logs: {'loss': 0.454, 'grad_norm': 5.074390411376953, 'learning_rate': 4.7409997409997415e-05, 'epoch': 0.3108003108003108}\n{'loss': 0.454, 'grad_norm': 5.074390411376953, 'learning_rate': 4.7409997409997415e-05, 'epoch': 0.3108003108003108}\nStep: 500 | Logs: {'loss': 0.3844, 'grad_norm': 7.825619220733643, 'learning_rate': 4.676249676249676e-05, 'epoch': 0.3885003885003885}\n{'loss': 0.3844, 'grad_norm': 7.825619220733643, 'learning_rate': 4.676249676249676e-05, 'epoch': 0.3885003885003885}\nStep: 600 | Logs: {'loss': 0.3101, 'grad_norm': 7.058714866638184, 'learning_rate': 4.611499611499612e-05, 'epoch': 0.4662004662004662}\n{'loss': 0.3101, 'grad_norm': 7.058714866638184, 'learning_rate': 4.611499611499612e-05, 'epoch': 0.4662004662004662}\nStep: 700 | Logs: {'loss': 0.3005, 'grad_norm': 7.541623115539551, 'learning_rate': 4.546749546749547e-05, 'epoch': 0.5439005439005439}\n{'loss': 0.3005, 'grad_norm': 7.541623115539551, 'learning_rate': 4.546749546749547e-05, 'epoch': 0.5439005439005439}\nStep: 800 | Logs: {'loss': 0.2885, 'grad_norm': 5.4660773277282715, 'learning_rate': 4.481999481999482e-05, 'epoch': 0.6216006216006216}\n{'loss': 0.2885, 'grad_norm': 5.4660773277282715, 'learning_rate': 4.481999481999482e-05, 'epoch': 0.6216006216006216}\nStep: 900 | Logs: {'loss': 0.2881, 'grad_norm': 21.618703842163086, 'learning_rate': 4.4172494172494175e-05, 'epoch': 0.6993006993006993}\n{'loss': 0.2881, 'grad_norm': 21.618703842163086, 'learning_rate': 4.4172494172494175e-05, 'epoch': 0.6993006993006993}\nStep: 1000 | Logs: {'loss': 0.2519, 'grad_norm': 4.820669174194336, 'learning_rate': 4.352499352499353e-05, 'epoch': 0.777000777000777}\n{'loss': 0.2519, 'grad_norm': 4.820669174194336, 'learning_rate': 4.352499352499353e-05, 'epoch': 0.777000777000777}\nStep: 1100 | Logs: {'loss': 0.2945, 'grad_norm': 8.978655815124512, 'learning_rate': 4.287749287749288e-05, 'epoch': 0.8547008547008547}\n{'loss': 0.2945, 'grad_norm': 8.978655815124512, 'learning_rate': 4.287749287749288e-05, 'epoch': 0.8547008547008547}\nStep: 1200 | Logs: {'loss': 0.2712, 'grad_norm': 1.4184015989303589, 'learning_rate': 4.222999222999223e-05, 'epoch': 0.9324009324009324}\n{'loss': 0.2712, 'grad_norm': 1.4184015989303589, 'learning_rate': 4.222999222999223e-05, 'epoch': 0.9324009324009324}\nEpoch 1.0 ended. Latest log: {'loss': 0.2712, 'grad_norm': 1.4184015989303589, 'learning_rate': 4.222999222999223e-05, 'epoch': 0.9324009324009324, 'step': 1200}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72f59cf4cbf14d7da013cb9be79d5904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b598453e7e34d119d63519e4f11e0c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c78bac85ca74014815869add5470824"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd196e6973ad44b3bde489505bcafe4d"}},"metadata":{}},{"name":"stdout","text":"Step: 1287 | Logs: {'eval_loss': 0.23569965362548828, 'eval_accuracy': 0.9085081585081585, 'eval_precision': 0.9554672134815528, 'eval_recall': 0.9238466703591698, 'eval_f1': 0.9325129266468789, 'eval_runtime': 26.4706, 'eval_samples_per_second': 194.48, 'eval_steps_per_second': 12.164, 'epoch': 1.0}\n{'eval_loss': 0.23569965362548828, 'eval_accuracy': 0.9085081585081585, 'eval_precision': 0.9554672134815528, 'eval_recall': 0.9238466703591698, 'eval_f1': 0.9325129266468789, 'eval_runtime': 26.4706, 'eval_samples_per_second': 194.48, 'eval_steps_per_second': 12.164, 'epoch': 1.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 1300 | Logs: {'loss': 0.241, 'grad_norm': 3.7618138790130615, 'learning_rate': 4.158249158249159e-05, 'epoch': 1.0101010101010102}\n{'loss': 0.241, 'grad_norm': 3.7618138790130615, 'learning_rate': 4.158249158249159e-05, 'epoch': 1.0101010101010102}\nStep: 1400 | Logs: {'loss': 0.2192, 'grad_norm': 1.0282785892486572, 'learning_rate': 4.0934990934990935e-05, 'epoch': 1.0878010878010878}\n{'loss': 0.2192, 'grad_norm': 1.0282785892486572, 'learning_rate': 4.0934990934990935e-05, 'epoch': 1.0878010878010878}\nStep: 1500 | Logs: {'loss': 0.2018, 'grad_norm': 1.6009060144424438, 'learning_rate': 4.028749028749029e-05, 'epoch': 1.1655011655011656}\n{'loss': 0.2018, 'grad_norm': 1.6009060144424438, 'learning_rate': 4.028749028749029e-05, 'epoch': 1.1655011655011656}\nStep: 1600 | Logs: {'loss': 0.2072, 'grad_norm': 1.3980671167373657, 'learning_rate': 3.9639989639989645e-05, 'epoch': 1.2432012432012431}\n{'loss': 0.2072, 'grad_norm': 1.3980671167373657, 'learning_rate': 3.9639989639989645e-05, 'epoch': 1.2432012432012431}\nStep: 1700 | Logs: {'loss': 0.2162, 'grad_norm': 3.437737226486206, 'learning_rate': 3.899248899248899e-05, 'epoch': 1.320901320901321}\n{'loss': 0.2162, 'grad_norm': 3.437737226486206, 'learning_rate': 3.899248899248899e-05, 'epoch': 1.320901320901321}\nStep: 1800 | Logs: {'loss': 0.2077, 'grad_norm': 4.07720422744751, 'learning_rate': 3.834498834498835e-05, 'epoch': 1.3986013986013985}\n{'loss': 0.2077, 'grad_norm': 4.07720422744751, 'learning_rate': 3.834498834498835e-05, 'epoch': 1.3986013986013985}\nStep: 1900 | Logs: {'loss': 0.2124, 'grad_norm': 2.6542394161224365, 'learning_rate': 3.76974876974877e-05, 'epoch': 1.4763014763014763}\n{'loss': 0.2124, 'grad_norm': 2.6542394161224365, 'learning_rate': 3.76974876974877e-05, 'epoch': 1.4763014763014763}\nStep: 2000 | Logs: {'loss': 0.2201, 'grad_norm': 0.9629464745521545, 'learning_rate': 3.704998704998705e-05, 'epoch': 1.554001554001554}\n{'loss': 0.2201, 'grad_norm': 0.9629464745521545, 'learning_rate': 3.704998704998705e-05, 'epoch': 1.554001554001554}\nStep: 2100 | Logs: {'loss': 0.1915, 'grad_norm': 1.0383715629577637, 'learning_rate': 3.6402486402486405e-05, 'epoch': 1.6317016317016317}\n{'loss': 0.1915, 'grad_norm': 1.0383715629577637, 'learning_rate': 3.6402486402486405e-05, 'epoch': 1.6317016317016317}\nStep: 2200 | Logs: {'loss': 0.1917, 'grad_norm': 1.453012466430664, 'learning_rate': 3.575498575498576e-05, 'epoch': 1.7094017094017095}\n{'loss': 0.1917, 'grad_norm': 1.453012466430664, 'learning_rate': 3.575498575498576e-05, 'epoch': 1.7094017094017095}\nStep: 2300 | Logs: {'loss': 0.2101, 'grad_norm': 1.7338581085205078, 'learning_rate': 3.510748510748511e-05, 'epoch': 1.7871017871017871}\n{'loss': 0.2101, 'grad_norm': 1.7338581085205078, 'learning_rate': 3.510748510748511e-05, 'epoch': 1.7871017871017871}\nStep: 2400 | Logs: {'loss': 0.205, 'grad_norm': 1.3705631494522095, 'learning_rate': 3.445998445998446e-05, 'epoch': 1.8648018648018647}\n{'loss': 0.205, 'grad_norm': 1.3705631494522095, 'learning_rate': 3.445998445998446e-05, 'epoch': 1.8648018648018647}\nStep: 2500 | Logs: {'loss': 0.1951, 'grad_norm': 3.260449171066284, 'learning_rate': 3.381248381248382e-05, 'epoch': 1.9425019425019425}\n{'loss': 0.1951, 'grad_norm': 3.260449171066284, 'learning_rate': 3.381248381248382e-05, 'epoch': 1.9425019425019425}\nEpoch 2.0 ended. Latest log: {'loss': 0.1951, 'grad_norm': 3.260449171066284, 'learning_rate': 3.381248381248382e-05, 'epoch': 1.9425019425019425, 'step': 2500}\nStep: 2574 | Logs: {'eval_loss': 0.23264656960964203, 'eval_accuracy': 0.9116161616161617, 'eval_precision': 0.9618424049502639, 'eval_recall': 0.9237995610412124, 'eval_f1': 0.9358294948071699, 'eval_runtime': 25.7881, 'eval_samples_per_second': 199.627, 'eval_steps_per_second': 12.486, 'epoch': 2.0}\n{'eval_loss': 0.23264656960964203, 'eval_accuracy': 0.9116161616161617, 'eval_precision': 0.9618424049502639, 'eval_recall': 0.9237995610412124, 'eval_f1': 0.9358294948071699, 'eval_runtime': 25.7881, 'eval_samples_per_second': 199.627, 'eval_steps_per_second': 12.486, 'epoch': 2.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 2600 | Logs: {'loss': 0.2067, 'grad_norm': 4.561190605163574, 'learning_rate': 3.3164983164983165e-05, 'epoch': 2.0202020202020203}\n{'loss': 0.2067, 'grad_norm': 4.561190605163574, 'learning_rate': 3.3164983164983165e-05, 'epoch': 2.0202020202020203}\nStep: 2700 | Logs: {'loss': 0.1753, 'grad_norm': 2.4652364253997803, 'learning_rate': 3.251748251748252e-05, 'epoch': 2.097902097902098}\n{'loss': 0.1753, 'grad_norm': 2.4652364253997803, 'learning_rate': 3.251748251748252e-05, 'epoch': 2.097902097902098}\nStep: 2800 | Logs: {'loss': 0.1886, 'grad_norm': 3.8966193199157715, 'learning_rate': 3.1869981869981875e-05, 'epoch': 2.1756021756021755}\n{'loss': 0.1886, 'grad_norm': 3.8966193199157715, 'learning_rate': 3.1869981869981875e-05, 'epoch': 2.1756021756021755}\nStep: 2900 | Logs: {'loss': 0.1684, 'grad_norm': 1.177351713180542, 'learning_rate': 3.122248122248122e-05, 'epoch': 2.2533022533022535}\n{'loss': 0.1684, 'grad_norm': 1.177351713180542, 'learning_rate': 3.122248122248122e-05, 'epoch': 2.2533022533022535}\nStep: 3000 | Logs: {'loss': 0.1839, 'grad_norm': 1.0610477924346924, 'learning_rate': 3.057498057498058e-05, 'epoch': 2.331002331002331}\n{'loss': 0.1839, 'grad_norm': 1.0610477924346924, 'learning_rate': 3.057498057498058e-05, 'epoch': 2.331002331002331}\nStep: 3100 | Logs: {'loss': 0.2115, 'grad_norm': 9.389792442321777, 'learning_rate': 2.992747992747993e-05, 'epoch': 2.4087024087024087}\n{'loss': 0.2115, 'grad_norm': 9.389792442321777, 'learning_rate': 2.992747992747993e-05, 'epoch': 2.4087024087024087}\nStep: 3200 | Logs: {'loss': 0.1642, 'grad_norm': 0.30982547998428345, 'learning_rate': 2.927997927997928e-05, 'epoch': 2.4864024864024863}\n{'loss': 0.1642, 'grad_norm': 0.30982547998428345, 'learning_rate': 2.927997927997928e-05, 'epoch': 2.4864024864024863}\nStep: 3300 | Logs: {'loss': 0.1742, 'grad_norm': 1.1547138690948486, 'learning_rate': 2.863247863247863e-05, 'epoch': 2.564102564102564}\n{'loss': 0.1742, 'grad_norm': 1.1547138690948486, 'learning_rate': 2.863247863247863e-05, 'epoch': 2.564102564102564}\nStep: 3400 | Logs: {'loss': 0.1826, 'grad_norm': 4.1920952796936035, 'learning_rate': 2.7984977984977983e-05, 'epoch': 2.641802641802642}\n{'loss': 0.1826, 'grad_norm': 4.1920952796936035, 'learning_rate': 2.7984977984977983e-05, 'epoch': 2.641802641802642}\nStep: 3500 | Logs: {'loss': 0.1816, 'grad_norm': 16.550352096557617, 'learning_rate': 2.733747733747734e-05, 'epoch': 2.7195027195027195}\n{'loss': 0.1816, 'grad_norm': 16.550352096557617, 'learning_rate': 2.733747733747734e-05, 'epoch': 2.7195027195027195}\nStep: 3600 | Logs: {'loss': 0.1689, 'grad_norm': 2.3586277961730957, 'learning_rate': 2.6689976689976692e-05, 'epoch': 2.797202797202797}\n{'loss': 0.1689, 'grad_norm': 2.3586277961730957, 'learning_rate': 2.6689976689976692e-05, 'epoch': 2.797202797202797}\nStep: 3700 | Logs: {'loss': 0.1678, 'grad_norm': 3.4206671714782715, 'learning_rate': 2.6042476042476044e-05, 'epoch': 2.874902874902875}\n{'loss': 0.1678, 'grad_norm': 3.4206671714782715, 'learning_rate': 2.6042476042476044e-05, 'epoch': 2.874902874902875}\nStep: 3800 | Logs: {'loss': 0.1879, 'grad_norm': 19.44211769104004, 'learning_rate': 2.5394975394975395e-05, 'epoch': 2.9526029526029527}\n{'loss': 0.1879, 'grad_norm': 19.44211769104004, 'learning_rate': 2.5394975394975395e-05, 'epoch': 2.9526029526029527}\nEpoch 3.0 ended. Latest log: {'loss': 0.1879, 'grad_norm': 19.44211769104004, 'learning_rate': 2.5394975394975395e-05, 'epoch': 2.9526029526029527, 'step': 3800}\nStep: 3861 | Logs: {'eval_loss': 0.2249973565340042, 'eval_accuracy': 0.9158896658896659, 'eval_precision': 0.9650682331996389, 'eval_recall': 0.929395589019462, 'eval_f1': 0.9401638321388078, 'eval_runtime': 25.843, 'eval_samples_per_second': 199.203, 'eval_steps_per_second': 12.46, 'epoch': 3.0}\n{'eval_loss': 0.2249973565340042, 'eval_accuracy': 0.9158896658896659, 'eval_precision': 0.9650682331996389, 'eval_recall': 0.929395589019462, 'eval_f1': 0.9401638321388078, 'eval_runtime': 25.843, 'eval_samples_per_second': 199.203, 'eval_steps_per_second': 12.46, 'epoch': 3.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 3900 | Logs: {'loss': 0.1891, 'grad_norm': 4.002619743347168, 'learning_rate': 2.474747474747475e-05, 'epoch': 3.0303030303030303}\n{'loss': 0.1891, 'grad_norm': 4.002619743347168, 'learning_rate': 2.474747474747475e-05, 'epoch': 3.0303030303030303}\nStep: 4000 | Logs: {'loss': 0.1726, 'grad_norm': 0.9375525712966919, 'learning_rate': 2.40999740999741e-05, 'epoch': 3.108003108003108}\n{'loss': 0.1726, 'grad_norm': 0.9375525712966919, 'learning_rate': 2.40999740999741e-05, 'epoch': 3.108003108003108}\nStep: 4100 | Logs: {'loss': 0.1652, 'grad_norm': 1.4255621433258057, 'learning_rate': 2.3452473452473453e-05, 'epoch': 3.185703185703186}\n{'loss': 0.1652, 'grad_norm': 1.4255621433258057, 'learning_rate': 2.3452473452473453e-05, 'epoch': 3.185703185703186}\nStep: 4200 | Logs: {'loss': 0.1778, 'grad_norm': 2.211275815963745, 'learning_rate': 2.2804972804972807e-05, 'epoch': 3.2634032634032635}\n{'loss': 0.1778, 'grad_norm': 2.211275815963745, 'learning_rate': 2.2804972804972807e-05, 'epoch': 3.2634032634032635}\nStep: 4300 | Logs: {'loss': 0.1772, 'grad_norm': 3.29191255569458, 'learning_rate': 2.215747215747216e-05, 'epoch': 3.341103341103341}\n{'loss': 0.1772, 'grad_norm': 3.29191255569458, 'learning_rate': 2.215747215747216e-05, 'epoch': 3.341103341103341}\nStep: 4400 | Logs: {'loss': 0.1781, 'grad_norm': 3.068631172180176, 'learning_rate': 2.150997150997151e-05, 'epoch': 3.4188034188034186}\n{'loss': 0.1781, 'grad_norm': 3.068631172180176, 'learning_rate': 2.150997150997151e-05, 'epoch': 3.4188034188034186}\nStep: 4500 | Logs: {'loss': 0.1789, 'grad_norm': 2.1963553428649902, 'learning_rate': 2.0862470862470865e-05, 'epoch': 3.4965034965034967}\n{'loss': 0.1789, 'grad_norm': 2.1963553428649902, 'learning_rate': 2.0862470862470865e-05, 'epoch': 3.4965034965034967}\nStep: 4600 | Logs: {'loss': 0.1897, 'grad_norm': 2.4631924629211426, 'learning_rate': 2.0214970214970216e-05, 'epoch': 3.5742035742035743}\n{'loss': 0.1897, 'grad_norm': 2.4631924629211426, 'learning_rate': 2.0214970214970216e-05, 'epoch': 3.5742035742035743}\nStep: 4700 | Logs: {'loss': 0.1733, 'grad_norm': 1.0542140007019043, 'learning_rate': 1.9567469567469568e-05, 'epoch': 3.651903651903652}\n{'loss': 0.1733, 'grad_norm': 1.0542140007019043, 'learning_rate': 1.9567469567469568e-05, 'epoch': 3.651903651903652}\nStep: 4800 | Logs: {'loss': 0.1645, 'grad_norm': 0.7960259318351746, 'learning_rate': 1.891996891996892e-05, 'epoch': 3.7296037296037294}\n{'loss': 0.1645, 'grad_norm': 0.7960259318351746, 'learning_rate': 1.891996891996892e-05, 'epoch': 3.7296037296037294}\nStep: 4900 | Logs: {'loss': 0.1728, 'grad_norm': 1.694854497909546, 'learning_rate': 1.8272468272468274e-05, 'epoch': 3.8073038073038075}\n{'loss': 0.1728, 'grad_norm': 1.694854497909546, 'learning_rate': 1.8272468272468274e-05, 'epoch': 3.8073038073038075}\nStep: 5000 | Logs: {'loss': 0.15, 'grad_norm': 1.442515254020691, 'learning_rate': 1.7624967624967625e-05, 'epoch': 3.885003885003885}\n{'loss': 0.15, 'grad_norm': 1.442515254020691, 'learning_rate': 1.7624967624967625e-05, 'epoch': 3.885003885003885}\nStep: 5100 | Logs: {'loss': 0.1674, 'grad_norm': 1.4555332660675049, 'learning_rate': 1.6977466977466977e-05, 'epoch': 3.9627039627039626}\n{'loss': 0.1674, 'grad_norm': 1.4555332660675049, 'learning_rate': 1.6977466977466977e-05, 'epoch': 3.9627039627039626}\nEpoch 4.0 ended. Latest log: {'loss': 0.1674, 'grad_norm': 1.4555332660675049, 'learning_rate': 1.6977466977466977e-05, 'epoch': 3.9627039627039626, 'step': 5100}\nStep: 5148 | Logs: {'eval_loss': 0.23498639464378357, 'eval_accuracy': 0.9176379176379177, 'eval_precision': 0.9533492951493394, 'eval_recall': 0.9526808927582606, 'eval_f1': 0.9473536962561535, 'eval_runtime': 25.7993, 'eval_samples_per_second': 199.541, 'eval_steps_per_second': 12.481, 'epoch': 4.0}\n{'eval_loss': 0.23498639464378357, 'eval_accuracy': 0.9176379176379177, 'eval_precision': 0.9533492951493394, 'eval_recall': 0.9526808927582606, 'eval_f1': 0.9473536962561535, 'eval_runtime': 25.7993, 'eval_samples_per_second': 199.541, 'eval_steps_per_second': 12.481, 'epoch': 4.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 5200 | Logs: {'loss': 0.1496, 'grad_norm': 1.5915040969848633, 'learning_rate': 1.632996632996633e-05, 'epoch': 4.040404040404041}\n{'loss': 0.1496, 'grad_norm': 1.5915040969848633, 'learning_rate': 1.632996632996633e-05, 'epoch': 4.040404040404041}\nStep: 5300 | Logs: {'loss': 0.1575, 'grad_norm': 2.696770191192627, 'learning_rate': 1.5682465682465683e-05, 'epoch': 4.118104118104118}\n{'loss': 0.1575, 'grad_norm': 2.696770191192627, 'learning_rate': 1.5682465682465683e-05, 'epoch': 4.118104118104118}\nStep: 5400 | Logs: {'loss': 0.1745, 'grad_norm': 2.1959807872772217, 'learning_rate': 1.5034965034965034e-05, 'epoch': 4.195804195804196}\n{'loss': 0.1745, 'grad_norm': 2.1959807872772217, 'learning_rate': 1.5034965034965034e-05, 'epoch': 4.195804195804196}\nStep: 5500 | Logs: {'loss': 0.1801, 'grad_norm': 0.2732304334640503, 'learning_rate': 1.4387464387464389e-05, 'epoch': 4.273504273504273}\n{'loss': 0.1801, 'grad_norm': 0.2732304334640503, 'learning_rate': 1.4387464387464389e-05, 'epoch': 4.273504273504273}\nStep: 5600 | Logs: {'loss': 0.1656, 'grad_norm': 1.197493553161621, 'learning_rate': 1.373996373996374e-05, 'epoch': 4.351204351204351}\n{'loss': 0.1656, 'grad_norm': 1.197493553161621, 'learning_rate': 1.373996373996374e-05, 'epoch': 4.351204351204351}\nStep: 5700 | Logs: {'loss': 0.1571, 'grad_norm': 2.3086137771606445, 'learning_rate': 1.3092463092463092e-05, 'epoch': 4.428904428904429}\n{'loss': 0.1571, 'grad_norm': 2.3086137771606445, 'learning_rate': 1.3092463092463092e-05, 'epoch': 4.428904428904429}\nStep: 5800 | Logs: {'loss': 0.1753, 'grad_norm': 1.529223918914795, 'learning_rate': 1.2444962444962445e-05, 'epoch': 4.506604506604507}\n{'loss': 0.1753, 'grad_norm': 1.529223918914795, 'learning_rate': 1.2444962444962445e-05, 'epoch': 4.506604506604507}\nStep: 5900 | Logs: {'loss': 0.1729, 'grad_norm': 1.3440759181976318, 'learning_rate': 1.1797461797461798e-05, 'epoch': 4.584304584304585}\n{'loss': 0.1729, 'grad_norm': 1.3440759181976318, 'learning_rate': 1.1797461797461798e-05, 'epoch': 4.584304584304585}\nStep: 6000 | Logs: {'loss': 0.1573, 'grad_norm': 0.5778716206550598, 'learning_rate': 1.114996114996115e-05, 'epoch': 4.662004662004662}\n{'loss': 0.1573, 'grad_norm': 0.5778716206550598, 'learning_rate': 1.114996114996115e-05, 'epoch': 4.662004662004662}\nStep: 6100 | Logs: {'loss': 0.1742, 'grad_norm': 1.05973219871521, 'learning_rate': 1.0502460502460502e-05, 'epoch': 4.73970473970474}\n{'loss': 0.1742, 'grad_norm': 1.05973219871521, 'learning_rate': 1.0502460502460502e-05, 'epoch': 4.73970473970474}\nStep: 6200 | Logs: {'loss': 0.158, 'grad_norm': 1.3054057359695435, 'learning_rate': 9.854959854959855e-06, 'epoch': 4.817404817404817}\n{'loss': 0.158, 'grad_norm': 1.3054057359695435, 'learning_rate': 9.854959854959855e-06, 'epoch': 4.817404817404817}\nStep: 6300 | Logs: {'loss': 0.1761, 'grad_norm': 1.007785677909851, 'learning_rate': 9.207459207459208e-06, 'epoch': 4.895104895104895}\n{'loss': 0.1761, 'grad_norm': 1.007785677909851, 'learning_rate': 9.207459207459208e-06, 'epoch': 4.895104895104895}\nStep: 6400 | Logs: {'loss': 0.1505, 'grad_norm': 4.901129245758057, 'learning_rate': 8.55995855995856e-06, 'epoch': 4.972804972804973}\n{'loss': 0.1505, 'grad_norm': 4.901129245758057, 'learning_rate': 8.55995855995856e-06, 'epoch': 4.972804972804973}\nEpoch 5.0 ended. Latest log: {'loss': 0.1505, 'grad_norm': 4.901129245758057, 'learning_rate': 8.55995855995856e-06, 'epoch': 4.972804972804973, 'step': 6400}\nStep: 6435 | Logs: {'eval_loss': 0.22451472282409668, 'eval_accuracy': 0.9184149184149184, 'eval_precision': 0.9520161110523737, 'eval_recall': 0.9547565244822548, 'eval_f1': 0.9481891240500308, 'eval_runtime': 25.7824, 'eval_samples_per_second': 199.671, 'eval_steps_per_second': 12.489, 'epoch': 5.0}\n{'eval_loss': 0.22451472282409668, 'eval_accuracy': 0.9184149184149184, 'eval_precision': 0.9520161110523737, 'eval_recall': 0.9547565244822548, 'eval_f1': 0.9481891240500308, 'eval_runtime': 25.7824, 'eval_samples_per_second': 199.671, 'eval_steps_per_second': 12.489, 'epoch': 5.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 6500 | Logs: {'loss': 0.1653, 'grad_norm': 3.4265902042388916, 'learning_rate': 7.912457912457913e-06, 'epoch': 5.05050505050505}\n{'loss': 0.1653, 'grad_norm': 3.4265902042388916, 'learning_rate': 7.912457912457913e-06, 'epoch': 5.05050505050505}\nStep: 6600 | Logs: {'loss': 0.1563, 'grad_norm': 4.222074031829834, 'learning_rate': 7.264957264957266e-06, 'epoch': 5.128205128205128}\n{'loss': 0.1563, 'grad_norm': 4.222074031829834, 'learning_rate': 7.264957264957266e-06, 'epoch': 5.128205128205128}\nStep: 6700 | Logs: {'loss': 0.1648, 'grad_norm': 2.350196361541748, 'learning_rate': 6.617456617456617e-06, 'epoch': 5.205905205905206}\n{'loss': 0.1648, 'grad_norm': 2.350196361541748, 'learning_rate': 6.617456617456617e-06, 'epoch': 5.205905205905206}\nStep: 6800 | Logs: {'loss': 0.1581, 'grad_norm': 1.6796776056289673, 'learning_rate': 5.96995596995597e-06, 'epoch': 5.283605283605284}\n{'loss': 0.1581, 'grad_norm': 1.6796776056289673, 'learning_rate': 5.96995596995597e-06, 'epoch': 5.283605283605284}\nStep: 6900 | Logs: {'loss': 0.172, 'grad_norm': 0.9191292524337769, 'learning_rate': 5.322455322455322e-06, 'epoch': 5.361305361305361}\n{'loss': 0.172, 'grad_norm': 0.9191292524337769, 'learning_rate': 5.322455322455322e-06, 'epoch': 5.361305361305361}\nStep: 7000 | Logs: {'loss': 0.1622, 'grad_norm': 1.7240403890609741, 'learning_rate': 4.6749546749546746e-06, 'epoch': 5.439005439005439}\n{'loss': 0.1622, 'grad_norm': 1.7240403890609741, 'learning_rate': 4.6749546749546746e-06, 'epoch': 5.439005439005439}\nStep: 7100 | Logs: {'loss': 0.1553, 'grad_norm': 1.3208786249160767, 'learning_rate': 4.027454027454028e-06, 'epoch': 5.516705516705517}\n{'loss': 0.1553, 'grad_norm': 1.3208786249160767, 'learning_rate': 4.027454027454028e-06, 'epoch': 5.516705516705517}\nStep: 7200 | Logs: {'loss': 0.1579, 'grad_norm': 2.0434393882751465, 'learning_rate': 3.3799533799533803e-06, 'epoch': 5.594405594405594}\n{'loss': 0.1579, 'grad_norm': 2.0434393882751465, 'learning_rate': 3.3799533799533803e-06, 'epoch': 5.594405594405594}\nStep: 7300 | Logs: {'loss': 0.173, 'grad_norm': 3.4886419773101807, 'learning_rate': 2.7324527324527325e-06, 'epoch': 5.672105672105672}\n{'loss': 0.173, 'grad_norm': 3.4886419773101807, 'learning_rate': 2.7324527324527325e-06, 'epoch': 5.672105672105672}\nStep: 7400 | Logs: {'loss': 0.1414, 'grad_norm': 2.0707828998565674, 'learning_rate': 2.084952084952085e-06, 'epoch': 5.74980574980575}\n{'loss': 0.1414, 'grad_norm': 2.0707828998565674, 'learning_rate': 2.084952084952085e-06, 'epoch': 5.74980574980575}\nStep: 7500 | Logs: {'loss': 0.1451, 'grad_norm': 0.7169891595840454, 'learning_rate': 1.4374514374514376e-06, 'epoch': 5.827505827505828}\n{'loss': 0.1451, 'grad_norm': 0.7169891595840454, 'learning_rate': 1.4374514374514376e-06, 'epoch': 5.827505827505828}\nStep: 7600 | Logs: {'loss': 0.1726, 'grad_norm': 3.5432417392730713, 'learning_rate': 7.899507899507899e-07, 'epoch': 5.905205905205905}\n{'loss': 0.1726, 'grad_norm': 3.5432417392730713, 'learning_rate': 7.899507899507899e-07, 'epoch': 5.905205905205905}\nStep: 7700 | Logs: {'loss': 0.137, 'grad_norm': 2.1205825805664062, 'learning_rate': 1.4245014245014247e-07, 'epoch': 5.982905982905983}\n{'loss': 0.137, 'grad_norm': 2.1205825805664062, 'learning_rate': 1.4245014245014247e-07, 'epoch': 5.982905982905983}\nEpoch 6.0 ended. Latest log: {'loss': 0.137, 'grad_norm': 2.1205825805664062, 'learning_rate': 1.4245014245014247e-07, 'epoch': 5.982905982905983, 'step': 7700}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 7722 | Logs: {'eval_loss': 0.25585126876831055, 'eval_accuracy': 0.918026418026418, 'eval_precision': 0.9515629845164707, 'eval_recall': 0.9535538531497736, 'eval_f1': 0.9473877938855221, 'eval_runtime': 25.656, 'eval_samples_per_second': 200.655, 'eval_steps_per_second': 12.551, 'epoch': 6.0}\n{'eval_loss': 0.25585126876831055, 'eval_accuracy': 0.918026418026418, 'eval_precision': 0.9515629845164707, 'eval_recall': 0.9535538531497736, 'eval_f1': 0.9473877938855221, 'eval_runtime': 25.656, 'eval_samples_per_second': 200.655, 'eval_steps_per_second': 12.551, 'epoch': 6.0}\nStep: 7722 | Logs: {'train_runtime': 2014.0643, 'train_samples_per_second': 61.336, 'train_steps_per_second': 3.834, 'total_flos': 8183427060243456.0, 'train_loss': 0.2247829725013067, 'epoch': 6.0}\n{'train_runtime': 2014.0643, 'train_samples_per_second': 61.336, 'train_steps_per_second': 3.834, 'train_loss': 0.2247829725013067, 'epoch': 6.0}\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7722, training_loss=0.2247829725013067, metrics={'train_runtime': 2014.0643, 'train_samples_per_second': 61.336, 'train_steps_per_second': 3.834, 'train_loss': 0.2247829725013067, 'epoch': 6.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"metrics = trainer.evaluate()\nprint(metrics)","metadata":{"_uuid":"9741349f-1213-4c7c-bd23-42e85d562179","_cell_guid":"5206324b-7c87-428d-9711-b8d53c7b9ea8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T20:09:12.140162Z","iopub.execute_input":"2025-04-17T20:09:12.140355Z","iopub.status.idle":"2025-04-17T20:09:37.832465Z","shell.execute_reply.started":"2025-04-17T20:09:12.140338Z","shell.execute_reply":"2025-04-17T20:09:37.831779Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step: 7722 | Logs: {'eval_loss': 0.22451472282409668, 'eval_accuracy': 0.9184149184149184, 'eval_precision': 0.9520161110523737, 'eval_recall': 0.9547565244822548, 'eval_f1': 0.9481891240500308, 'eval_runtime': 25.6662, 'eval_samples_per_second': 200.575, 'eval_steps_per_second': 12.546, 'epoch': 6.0}\n{'eval_loss': 0.22451472282409668, 'eval_accuracy': 0.9184149184149184, 'eval_precision': 0.9520161110523737, 'eval_recall': 0.9547565244822548, 'eval_f1': 0.9481891240500308, 'eval_runtime': 25.6662, 'eval_samples_per_second': 200.575, 'eval_steps_per_second': 12.546, 'epoch': 6.0}\n{'eval_loss': 0.22451472282409668, 'eval_accuracy': 0.9184149184149184, 'eval_precision': 0.9520161110523737, 'eval_recall': 0.9547565244822548, 'eval_f1': 0.9481891240500308, 'eval_runtime': 25.6662, 'eval_samples_per_second': 200.575, 'eval_steps_per_second': 12.546, 'epoch': 6.0}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"test_text = \"Patient has chronic glossitis and possible environmental inhalant allergies...\"\ninputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n\ninputs = {key: value.to(device) for key, value in inputs.items()}\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class_id = logits.argmax().item()\n\npredicted_label = label2id.get(predicted_class_id)\nprint(\"Predicted medical field:\", predicted_label)","metadata":{"_uuid":"872c35ae-7a10-4663-adeb-26bb6b786b45","_cell_guid":"997c1c05-0158-44d9-94f8-3c2a5a8231d4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-17T20:09:37.833350Z","iopub.execute_input":"2025-04-17T20:09:37.833633Z","iopub.status.idle":"2025-04-17T20:09:37.895543Z","shell.execute_reply.started":"2025-04-17T20:09:37.833598Z","shell.execute_reply":"2025-04-17T20:09:37.894906Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Predicted medical field: Dermatologist\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(id2label)\nprint(label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:39:17.595831Z","iopub.execute_input":"2025-04-17T20:39:17.596190Z","iopub.status.idle":"2025-04-17T20:39:17.601110Z","shell.execute_reply.started":"2025-04-17T20:39:17.596163Z","shell.execute_reply":"2025-04-17T20:39:17.600127Z"}},"outputs":[{"name":"stdout","text":"{'Alergist': 0, 'Cardiologist': 1, 'Dermatologist': 2, 'Endocrinologist': 3, 'Gastroenterologist': 4, 'Genetics': 5, 'Geriatrics': 6, 'Neurologist': 7, 'Oncologist/Hematologist': 8, 'Orthopedics': 9, 'OtherQA': 10}\n{0: 'Alergist', 1: 'Cardiologist', 2: 'Dermatologist', 3: 'Endocrinologist', 4: 'Gastroenterologist', 5: 'Genetics', 6: 'Geriatrics', 7: 'Neurologist', 8: 'Oncologist/Hematologist', 9: 'Orthopedics', 10: 'OtherQA'}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\n\ninput_text = \"A 58‑year‑old patient presents with intermittent chest pain, shortness of breath on exertion, and palpitations. Which specialist should they be referred to?\"\ninputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ninputs = {k: v.to(device) for k, v in inputs.items()}\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class_id = torch.argmax(logits, dim=1).item()\n\n\npredicted_label = id2label[predicted_class_id]\nprint(\"Predicted medical field:\", predicted_label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T20:46:23.139665Z","iopub.execute_input":"2025-04-17T20:46:23.140055Z","iopub.status.idle":"2025-04-17T20:46:23.161924Z","shell.execute_reply.started":"2025-04-17T20:46:23.140024Z","shell.execute_reply":"2025-04-17T20:46:23.161010Z"}},"outputs":[{"name":"stdout","text":"Predicted medical field: Cardiologist\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}