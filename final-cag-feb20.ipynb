{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10810877,"sourceType":"datasetVersion","datasetId":6711034}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"5e9744cc-8bf9-47ec-9bab-34faf81e53b6","_cell_guid":"96ca6daf-1683-4cf7-b376-63f1b72b9964","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T13:15:17.459630Z","iopub.execute_input":"2025-04-21T13:15:17.459831Z","iopub.status.idle":"2025-04-21T13:15:17.491354Z","shell.execute_reply.started":"2025-04-21T13:15:17.459805Z","shell.execute_reply":"2025-04-21T13:15:17.490766Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"/kaggle/input/qa-dataset-medical-llm/growth_hormone_receptorQA.csv\n/kaggle/input/qa-dataset-medical-llm/MedicalQuestionAnswering.csv\n/kaggle/input/qa-dataset-medical-llm/Disease_Control_and_PreventionQA.csv\n/kaggle/input/qa-dataset-medical-llm/Genetic_and_Rare_DiseasesQA.csv\n/kaggle/input/qa-dataset-medical-llm/Diabetes_and_Digestive_and_Kidney_DiseasesQA.csv\n/kaggle/input/qa-dataset-medical-llm/CancerQA.csv\n/kaggle/input/qa-dataset-medical-llm/Neurological_Disorders_and_StrokeQA.csv\n/kaggle/input/qa-dataset-medical-llm/Heart_Lung_and_BloodQA.csv\n/kaggle/input/qa-dataset-medical-llm/SeniorHealthQA.csv\n/kaggle/input/qa-dataset-medical-llm/OtherQA.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"! pip install transformers bitsandbytes","metadata":{"_uuid":"fc2f6819-44ff-4189-a2a5-cfdd0fa0932d","_cell_guid":"16f3ca65-4e19-49ba-86af-6e42cb6cf9b7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T13:15:17.491947Z","iopub.execute_input":"2025-04-21T13:15:17.492166Z","iopub.status.idle":"2025-04-21T13:15:26.737294Z","shell.execute_reply.started":"2025-04-21T13:15:17.492147Z","shell.execute_reply":"2025-04-21T13:15:26.736288Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport argparse\nimport os\nimport json\nfrom time import time\nfrom sentence_transformers import SentenceTransformer, util\nfrom transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\nfrom transformers.cache_utils import DynamicCache\nimport random\nimport bitsandbytes as bnb","metadata":{"_uuid":"0737945c-180f-4e67-844d-c0b75918f293","_cell_guid":"9582465d-c130-4f1e-b8cc-124a1d1f9d62","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:15:26.738318Z","iopub.execute_input":"2025-04-21T13:15:26.738565Z","iopub.status.idle":"2025-04-21T13:16:03.010156Z","shell.execute_reply.started":"2025-04-21T13:15:26.738545Z","shell.execute_reply":"2025-04-21T13:16:03.009373Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"HF_TOKEN = \"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\"\nglobal model_name, model, tokenizer\nglobal rand_seed","metadata":{"_uuid":"6d1a8dfb-6117-421d-8c8e-19eb2a789f73","_cell_guid":"2b9efa5f-b59e-4f23-b8f0-057fd5c6e00d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:03.010942Z","iopub.execute_input":"2025-04-21T13:16:03.011631Z","iopub.status.idle":"2025-04-21T13:16:03.015252Z","shell.execute_reply.started":"2025-04-21T13:16:03.011587Z","shell.execute_reply":"2025-04-21T13:16:03.014414Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def generate(model, input_ids: torch.Tensor, past_key_values, max_new_tokens: int = 300) -> torch.Tensor:\n    \n    \"\"\"\n    Generate text with greedy decoding.\n\n    Args:\n        model: HuggingFace model with automatic device mapping\n        input_ids: Input token ids\n        past_key_values: KV Cache for knowledge\n        max_new_tokens: Maximum new tokens to generate\n    \"\"\"\n\n    embed_device = model.model.embed_tokens.weight.device\n\n    origin_ids = input_ids\n    input_ids = input_ids.to(embed_device)\n\n    output_ids = input_ids.clone()\n    next_token = input_ids\n\n    with torch.no_grad():\n        for _ in range(max_new_tokens):\n            outputs = model(\n                input_ids=next_token, \n                past_key_values=past_key_values,\n                use_cache=True\n            )\n            next_token_logits = outputs.logits[:, -1, :]\n            next_token = next_token_logits.argmax(dim=-1).unsqueeze(-1)\n            next_token = next_token.to(embed_device)\n\n            past_key_values = outputs.past_key_values\n\n            output_ids = torch.cat([output_ids, next_token], dim=1)\n\n            if next_token.item() in model.config.eos_token_id:\n                break\n    return output_ids[:, origin_ids.shape[-1]:]","metadata":{"_uuid":"ca0d0a93-955a-4011-964a-dfd1c670bb69","_cell_guid":"4e41352b-a390-4d29-8031-6cb3ac581e5e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:03.016325Z","iopub.execute_input":"2025-04-21T13:16:03.016632Z","iopub.status.idle":"2025-04-21T13:16:03.981751Z","shell.execute_reply.started":"2025-04-21T13:16:03.016601Z","shell.execute_reply":"2025-04-21T13:16:03.981048Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\"\"\"KV Cache test\"\"\"\n# Allowlist the DynamicCache class\ntorch.serialization.add_safe_globals([DynamicCache])\ntorch.serialization.add_safe_globals([set])\n\ndef preprocess_knowledge(model, tokenizer, prompt: str,) -> DynamicCache:\n    \"\"\"\n    Prepare knowledge kv cache for CAG.\n    Args:\n        model: HuggingFace model with automatic device mapping\n        tokenizer: HuggingFace tokenizer\n        prompt: The knowledge to preprocess, which is basically a prompt\n\n    Returns:\n        DynamicCache: KV Cache\n    \"\"\"\n    embed_device = model.model.embed_tokens.weight.device\n    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(embed_device)\n    past_key_values = DynamicCache()\n    with torch.no_grad():\n        outputs = model(\n            input_ids=input_ids,\n            past_key_values=past_key_values,\n            use_cache=True,\n            output_attentions=False,\n            output_hidden_states=False\n        )\n    return outputs.past_key_values","metadata":{"_uuid":"5d863351-3fde-4c12-b421-8c365b0dea56","_cell_guid":"6c44f824-ebbf-4533-923a-a21970bc4957","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:03.984091Z","iopub.execute_input":"2025-04-21T13:16:03.984319Z","iopub.status.idle":"2025-04-21T13:16:04.002274Z","shell.execute_reply.started":"2025-04-21T13:16:03.984299Z","shell.execute_reply":"2025-04-21T13:16:04.001609Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def write_kv_cache(kv: DynamicCache, path: str):\n    \"\"\"\n    Write the KV Cache to a file.\n    \"\"\"\n    torch.save(kv, path)\n\n\ndef clean_up(kv: DynamicCache, origin_len: int):\n    \"\"\"\n    Truncate the KV Cache to the original length.\n    \"\"\"\n    for i in range(len(kv.key_cache)):\n        kv.key_cache[i] = kv.key_cache[i][:, :, :origin_len, :]\n        kv.value_cache[i] = kv.value_cache[i][:, :, :origin_len, :]\n\n\ndef read_kv_cache(path: str) -> DynamicCache:\n    \"\"\"\n    Read the KV Cache from a file.\n    \"\"\"\n    kv = torch.load(path, weights_only=True)\n    return kv","metadata":{"_uuid":"5f7198da-a84c-4b2e-af45-0271117cb7e1","_cell_guid":"ca134d65-8a0e-4e53-95da-9b9f71d3b878","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:04.003623Z","iopub.execute_input":"2025-04-21T13:16:04.003923Z","iopub.status.idle":"2025-04-21T13:16:04.028198Z","shell.execute_reply.started":"2025-04-21T13:16:04.003902Z","shell.execute_reply":"2025-04-21T13:16:04.027601Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nbert_model = SentenceTransformer('all-MiniLM-L6-v2')  # Use a lightweight sentence-transformer\n\ndef get_bert_similarity(response, ground_truth):\n    # Encode the query and text\n    query_embedding = bert_model.encode(response, convert_to_tensor=True)\n    text_embedding = bert_model.encode(ground_truth, convert_to_tensor=True)\n\n    # Compute the cosine similarity between the query and text\n    cosine_score = util.pytorch_cos_sim(query_embedding, text_embedding)\n\n    return cosine_score.item()","metadata":{"_uuid":"fe4077f2-58a4-401f-ad28-122e5fbdd5b4","_cell_guid":"2bcb95d4-e338-407b-912b-7103302ec310","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T13:16:04.028958Z","iopub.execute_input":"2025-04-21T13:16:04.029212Z","iopub.status.idle":"2025-04-21T13:16:07.560785Z","shell.execute_reply.started":"2025-04-21T13:16:04.029193Z","shell.execute_reply":"2025-04-21T13:16:07.560126Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf91420d07524ae7ac0d36543caed2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06a2cb27b82744e9b3fb199c177ac7e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ebb6721af8b48eaaaed8ed6e120150e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0c8ff8d2c24ce5a961e79b847a2c31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2ccbc91ae584f97ad468c52eb6bc582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f82d5e6db7843f2b12a285e6d2623e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd08e2f9ad14be29d953c6f6ab0fded"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8ae56f50e51452ea2f1d508963f163a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4bed3d8c1144c478db11325b793e04d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84bcdacf803e40969d402103deca6f86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f544c2e7139489685045570b12f6f92"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def prepare_kvcache(documents, filepath: str = \"/kaggle/working/cache_knowledges.pt\", answer_instruction: str = None):\n    # Prepare the knowledges kvcache\n\n    if answer_instruction is None:\n        answer_instruction = \"Answer the question with a super short answer.\"\n    knowledges = f\"\"\"\n    <|begin_of_text|>\n    <|start_header_id|>system<|end_header_id|>\n    You are a medical assistant providing concise and factual answers in the field. <|eot_id|>\n    <|start_header_id|>user<|end_header_id|>\n    Context information is bellow.\n    ------------------------------------------------\n    {documents}\n    ------------------------------------------------\n    {answer_instruction}\n    Question:\n    \"\"\"\n    # Get the knowledge cache\n    t1 = time()\n    kv = preprocess_knowledge(model, tokenizer, knowledges)\n    print(\"kvlen: \", kv.key_cache[0].shape[-2])\n    write_kv_cache(kv, filepath)\n    t2 = time()\n    return kv, t2 - t1","metadata":{"_uuid":"7ca3b623-3746-4222-82cd-078e8d42a5f5","_cell_guid":"4a950028-cab7-4883-9873-501ae30656c6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.561522Z","iopub.execute_input":"2025-04-21T13:16:07.561730Z","iopub.status.idle":"2025-04-21T13:16:07.566391Z","shell.execute_reply.started":"2025-04-21T13:16:07.561713Z","shell.execute_reply":"2025-04-21T13:16:07.565739Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"'''\n****** BELOW CODE IS FOR DATASET FORMATING ******\n\n'''\n\ndef get_kis_dataset(filepath: str):\n    df = pd.read_csv(filepath)\n    dataset = zip(df['Question'], df['Answer'])\n    text_list = df[\"topic\"].to_list()\n\n    return text_list, dataset","metadata":{"_uuid":"0eee797d-1c5d-4f3e-88c6-916a24fa8c65","_cell_guid":"e487f05b-91f2-4871-aef8-38149e8fb733","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.567248Z","iopub.execute_input":"2025-04-21T13:16:07.567545Z","iopub.status.idle":"2025-04-21T13:16:07.629218Z","shell.execute_reply.started":"2025-04-21T13:16:07.567519Z","shell.execute_reply":"2025-04-21T13:16:07.628346Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"_uuid":"bf900cac-d688-4eea-be9f-ad5b6e7c24f0","_cell_guid":"94af6e01-a850-4a53-a431-41d6814e4a46","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def kvcache_test(args: argparse.Namespace):\n    answer_instruction = None\n    if args.dataset == \"kis_sample\":\n        datapath = \"/kaggle/input/qa-dataset-medical-llm/Diabetes_and_Digestive_and_Kidney_DiseasesQA.csv\"\n        text_list, dataset = get_kis_dataset(datapath)\n        \n\n    kvcache_path = \"/kaggle/working/cache_knowledges.pt\"\n\n    knowledges = '\\n\\n\\n\\n\\n\\n'.join(text_list) # this is used to convert different type of knowledge into a single string with spaces (\\n)\n\n\n    knowledge_cache, prepare_time = prepare_kvcache(knowledges, filepath = kvcache_path, answer_instruction = answer_instruction)\n    kv_len = knowledge_cache.key_cache[0].shape[-2]\n\n    print(f\"KVcache prepared in {prepare_time} seconds\")\n    with open(args.output, \"a\") as f:\n        f.write(f\"KVcache prepared in {prepare_time} seconds\\n\")\n\n    results = {\n        \"cache_time\": [],\n        \"generate_time\": [],\n        \"similarity\": [],\n        \"prompts\": [],\n        \"responses\": []\n    }\n\n    dataset = list(dataset)  # Convert the dataset to a list\n\n    max_questions = min(len(dataset), args.maxQuestion) if args.maxQuestion is not None else len(dataset)\n    # Retrieve the knowledge from the vector database\n    for id, (question, ground_truth) in enumerate(dataset[:max_questions]):\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n\n        # Read the knowledge cache from the cache file\n        cache_t1 = time()\n        \n        if args.kvcache == \"file\":\n            knowledge_cache = read_kv_cache(kvcache_path)\n\n        # Not a good idea to use this method, as it will consume a lot of memory\n        # if args.kvcache == \"variable\":\n        #     knowledge_cache = documents_cache\n        cache_t2 = time()\n\n        # Generate Response for the question\n        knowledges = '\\n\\n\\n'.join(text_list)\n\n        if args.usePrompt:\n            prompt = f\"\"\"\n            <|begin_of_text|>\n            <|start_header_id|>system<|end_header_id|>\n            You are an assistant for giving short answers based on given context.<|eot_id|>\n            <|start_header_id|>user<|end_header_id|>\n            Context information is bellow.\n            ------------------------------------------------\n            {knowledges}\n            ------------------------------------------------\n            {answer_instruction}\n            Question:\n            {question}<|eot_id|>\n            <|start_header_id|>assistant<|end_header_id|>\n            \"\"\"\n            generate_t1 = time()\n            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n            output = generate(model, input_ids, DynamicCache())\n            generated_text = tokenizer.decode(output[0], skip_special_tokens=True, temperature=None)\n            generate_t2 = time()\n        else:\n            prompt = f\"\"\"\n            {question}<|eot_id|>\n            <|start_header_id|>assistant<|end_header_id|>\n            \"\"\"\n            generate_t1 = time()\n            clean_up(knowledge_cache, kv_len)\n            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n            output = generate(model, input_ids, knowledge_cache)\n            generated_text = tokenizer.decode(output[0], skip_special_tokens=True, temperature=None)\n            generate_t2 = time()\n\n        # print(\"D: \", knowledges)\n        print(\"Q: \", question)\n        print(\"A: \", generated_text)\n\n        \n        # Evaluate bert-score similarity\n        similarity = get_bert_similarity(generated_text, ground_truth)\n\n        print(f\"[{id}]: Semantic Similarity: {round(similarity, 5)},\",\n              f\"cache time: {cache_t2 - cache_t1},\",\n              f\"generate time: {generate_t2 - generate_t1}\")\n        with open(args.output, \"a\") as f:\n            f.write(f\"[{id}]: Semantic Similarity: {round(similarity, 5)},\\t cache time: {cache_t2 -   cache_t1},\\t generate time: {generate_t2 - generate_t1}\\n\")\n\n        results[\"prompts\"].append(question)\n        results[\"responses\"].append(generated_text)\n        results[\"cache_time\"].append(cache_t2 - cache_t1)\n        results[\"generate_time\"].append(generate_t2 - generate_t1)\n        results[\"similarity\"].append(similarity)\n\n        with open(args.output, \"a\") as f:\n            f.write(f\"[{id}]: [Cumulative]: \"\n                    + f\"Semantic Similarity: {round(sum(results['similarity']) / (len(results['similarity'])) , 5)},\"\n                    + f\"\\t cache time: {sum(results['cache_time']) / (len(results['cache_time'])) },\"\n                    + f\"\\t generate time: {sum(results['generate_time']) / (len(results['generate_time'])) }\\n\")\n\n    avg_similarity = sum(results[\"similarity\"]) / len(results[\"similarity\"])\n    avg_cache_time = sum(results[\"cache_time\"]) / len(results[\"cache_time\"])\n    avg_generate_time = sum(results[\"generate_time\"]) / len(results[\"generate_time\"])\n    print()\n    print(f\"Prepare time: {prepare_time}\")\n    print(f\"Average Semantic Similarity: {avg_similarity}\")\n    print(f\"cache time: {avg_cache_time},\\t generate time: {avg_generate_time}\")\n    print()\n    with open(args.output, \"a\") as f:\n        f.write(\"\\n\")\n        f.write(f\"Result for {args.output}\\n\")\n        f.write(f\"Prepare time: {prepare_time}\\n\")\n        f.write(f\"Average Semantic Similarity: {avg_similarity}\\n\")\n        f.write(f\"cache time: {avg_cache_time},\\t generate time: {avg_generate_time}\\n\")","metadata":{"_uuid":"033e841e-6185-4d54-a711-c7337e0ac2cf","_cell_guid":"460660c3-a614-4a33-b44a-93036fb19909","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.630024Z","iopub.execute_input":"2025-04-21T13:16:07.630331Z","iopub.status.idle":"2025-04-21T13:16:07.648581Z","shell.execute_reply.started":"2025-04-21T13:16:07.630303Z","shell.execute_reply":"2025-04-21T13:16:07.647978Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Define quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,              # Load model in 4-bit precision\n    bnb_4bit_quant_type=\"nf4\",      # Normalize float 4 quantization\n    bnb_4bit_compute_dtype=torch.float16,  # Compute dtype for 4-bit base matrices\n    bnb_4bit_use_double_quant=True  # Use nested quantization\n)","metadata":{"_uuid":"8086a815-3227-48bd-8828-7e002abefe40","_cell_guid":"a7dcf4b3-218a-4492-abe8-e538c70c6a67","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.649312Z","iopub.execute_input":"2025-04-21T13:16:07.649654Z","iopub.status.idle":"2025-04-21T13:16:07.673286Z","shell.execute_reply.started":"2025-04-21T13:16:07.649624Z","shell.execute_reply":"2025-04-21T13:16:07.672541Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def load_quantized_model(model_name, hf_token=None):\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_name,\n        token=hf_token\n    )\n\n    # Load model with quantization\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        device_map=\"auto\",          # Automatically choose best device\n        trust_remote_code=True,     # Required for some models\n        token=hf_token\n    )\n\n    return tokenizer, model","metadata":{"_uuid":"e8eee477-5377-40e1-a04b-6dce519e2cd3","_cell_guid":"d6255eb7-b7eb-4fa7-bdf1-f92b06a6a328","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.673988Z","iopub.execute_input":"2025-04-21T13:16:07.674280Z","iopub.status.idle":"2025-04-21T13:16:07.691189Z","shell.execute_reply.started":"2025-04-21T13:16:07.674254Z","shell.execute_reply":"2025-04-21T13:16:07.690584Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n\n    import sys\n    sys.argv = [sys.argv[0]]\n    # args = parser.parse_args()\n     \n    args = argparse.Namespace(\n        modelname=\"meta-llama/Llama-3.2-3B-Instruct\",  # or any model name you prefer\n        quantized=True,\n        kvcache=\"file\",\n        similarity=\"bertscore\",\n        output=\"results.txt\",\n        maxQuestion=10,      # set your desired maximum number of questions\n        maxKnowledge=50,     # set your desired maximum number of knowledge items\n        maxParagraph=5,      # set your desired maximum number of paragraphs\n        usePrompt=False,     # whether to bypass the cache\n        dataset=\"kis_sample\",# or another allowed dataset choice\n        randomSeed=42\n    )\n    # 48 Articles, each article average 40~50 paragraph, each average 5~10 questions\n\n    # args = parser.parse_args()\n\n    print(\"maxKnowledge\", args.maxKnowledge, \"maxParagraph\", args.maxParagraph, \"maxQuestion\", args.maxQuestion, \"randomeSeed\", args.randomSeed)\n\n    model_name = args.modelname\n    rand_seed = args.randomSeed if args.randomSeed is not None else None\n\n\n    # Define local model cache directory\n    local_model_dir = \"/kaggle/working/saved_model\"\n\n    if os.path.exists(local_model_dir):\n        print(\"Loading model from local cache.\")\n        tokenizer = AutoTokenizer.from_pretrained(local_model_dir)\n        model = AutoModelForCausalLM.from_pretrained(\n            local_model_dir,\n            torch_dtype=torch.float16,\n            device_map=\"auto\"\n        )\n    else:\n        print(\"Downloading model from Hugging Face and saving locally.\")\n        if args.quantized:\n            tokenizer, model = load_quantized_model(model_name=model_name, hf_token=HF_TOKEN)\n        else:\n            print(\"line 46 in running\")\n            tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n            model = AutoModelForCausalLM.from_pretrained(\n                model_name,\n                torch_dtype=torch.float16,\n                device_map=\"auto\",\n                token=HF_TOKEN\n            )\n        os.makedirs(local_model_dir, exist_ok=True)\n        tokenizer.save_pretrained(local_model_dir)\n        model.save_pretrained(local_model_dir)\n\n    def unique_path(path, i=0):\n        if os.path.exists(path):\n            # path = path.split(\"_\")[:-1] if i != 0 else path\n            return unique_path(path + \"_\" + str(i), i + 1)\n        return path\n\n    if os.path.exists(args.output):\n        args.output = unique_path(args.output)\n\n    kvcache_test(args)\n\n\n    # ------------------------------\n    # Interactive Query Input\n    # ------------------------------\n    \n    print(\"\\nInteractive Query Mode:\")\n    user_query = input(\"Enter your query: \")\n    # Tokenize the query with attention_mask and pad_token_id (if needed)\n    inputs = tokenizer(user_query, return_tensors=\"pt\").to(model.device)\n    output = model.generate(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        max_new_tokens=300,  # maximum generated tokens\n        do_sample=False,     # greedy decoding\n        temperature=None,\n        pad_token_id=tokenizer.eos_token_id  # explicitly set pad token id\n    )\n    generated_answer = tokenizer.decode(output[0], skip_special_tokens=True)\n    print(\"Generated Answer:\\n\", generated_answer)","metadata":{"_uuid":"d63d93d0-595b-48eb-8a96-dcd2e08c6046","_cell_guid":"177d2c26-1bda-4b96-b073-73f32f3a90ed","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-21T13:16:07.691862Z","iopub.execute_input":"2025-04-21T13:16:07.692114Z","iopub.status.idle":"2025-04-21T13:18:38.360281Z","shell.execute_reply.started":"2025-04-21T13:16:07.692082Z","shell.execute_reply":"2025-04-21T13:18:38.359377Z"}},"outputs":[{"name":"stdout","text":"maxKnowledge 50 maxParagraph 5 maxQuestion 10 randomeSeed 42\nDownloading model from Hugging Face and saving locally.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe6eba6d9dda4cff81822338ade55039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c774f6bc649a4c12bd297306704f520a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca21d13f915b4059aabc27ac0ee720b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9255781844a14148be5b09f2e6a1e316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c412418cfa545ecbbd167db39f804a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cf2cb2c53bf4439be551640568757be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14a945b66a434f8db66f8ff9b082a70a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a03883d191349d9a1e59c79958ac818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c241413b7d443d185fa58a44bfce9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2868982f554f3ca4e28ae06b169029"}},"metadata":{}},{"name":"stdout","text":"kvlen:  10788\nKVcache prepared in 7.623744964599609 seconds\nQ:  What is (are) Kidney Stones in Adults ?\nA:   Kidney stones are small, hard mineral deposits that form inside the kidneys and can cause severe pain, nausea, and vomiting.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa013f7a51404ff3acad92fbb4134b21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495bfeea04c64ff2a62dbb65ba32f205"}},"metadata":{}},{"name":"stdout","text":"[0]: Semantic Similarity: 0.7088, cache time: 1.0868916511535645, generate time: 2.6084437370300293\nQ:  What is (are) Kidney Stones in Adults ?\nA:   Kidney stones are small, hard mineral deposits that form inside the kidneys and can cause severe pain, nausea, and vomiting.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"748b984a1959443480bb91a7ebd11ed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c83a33b92bd44ccb7f9791d85393db7"}},"metadata":{}},{"name":"stdout","text":"[1]: Semantic Similarity: 0.34835, cache time: 0.963425874710083, generate time: 2.387451171875\nQ:  Who is at risk for Kidney Stones in Adults? ?\nA:   Adults with a family history of kidney stones, obesity, and certain medical conditions such as gout, inflammatory bowel disease, and diabetes are at risk for kidney stones.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f87c8e15ce3438f9f0ece6051c6317c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cceec55e75224e3cb664c961d60a6a2c"}},"metadata":{}},{"name":"stdout","text":"[2]: Semantic Similarity: 0.62322, cache time: 0.7496263980865479, generate time: 3.1089179515838623\nQ:  What causes Kidney Stones in Adults ?\nA:   High levels of calcium, oxalate, and uric acid in the urine can cause kidney stones.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c659a7dc622f421ab605daaf25538fb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c569c048f5f14fb6941e87295449a206"}},"metadata":{}},{"name":"stdout","text":"[3]: Semantic Similarity: 0.76859, cache time: 0.5776271820068359, generate time: 2.0364012718200684\nQ:  What is (are) Kidney Stones in Adults ?\nA:   Kidney stones are small, hard mineral deposits that form inside the kidneys and can cause severe pain, nausea, and vomiting.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36899ecb2c3e4563ac6e6cfc09cf9b91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da42c6263c944cbda0419bf504bf3e1d"}},"metadata":{}},{"name":"stdout","text":"[4]: Semantic Similarity: 0.60279, cache time: 0.5637047290802002, generate time: 2.392669677734375\nQ:  What are the symptoms of Kidney Stones in Adults ?\nA:   Pain in the flank or side, nausea, vomiting, frequent urination, blood in the urine, and fever.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca6675c3f0f4681964694931cd45416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeab497ad14b408d8368c709dc5b0292"}},"metadata":{}},{"name":"stdout","text":"[5]: Semantic Similarity: 0.49642, cache time: 0.5644688606262207, generate time: 2.2151362895965576\nQ:  How to diagnose Kidney Stones in Adults ?\nA:   A kidney stone can be diagnosed through a combination of physical examination, medical history, and imaging tests such as ultrasound, CT scan, or X-ray.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecc305a1eda410396e577eb8d8e0835"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"caa5ba78f75b47a9852f1e73d8538355"}},"metadata":{}},{"name":"stdout","text":"[6]: Semantic Similarity: 0.80736, cache time: 0.5675647258758545, generate time: 2.8420257568359375\nQ:  What are the treatments for Kidney Stones in Adults ?\nA:   Treatment for kidney stones in adults typically involves a combination of the following:\n\n1. **Pain management**: Over-the-counter pain medications such as acetaminophen or ibuprofen to manage pain and discomfort.\n2. **Fluids**: Drinking plenty of water to help flush out the stone and prevent future occurrences.\n3. **Medications**: In some cases, medications such as alpha-blockers or pain medications may be prescribed to help manage symptoms.\n4. **Surgery**: In severe cases, surgical removal of the stone (nephrolithotomy) may be necessary.\n5. **Lithotripsy**: A minimally invasive procedure that uses shock waves to break up the stone.\n6. **Ureteroscopy**: A procedure where a small scope is inserted through the urethra and bladder to remove the stone.\n7. **Percutaneous nephrolithotomy**: A minimally invasive procedure where a small incision is made in the back to remove the stone.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc3005aba8845e09e8a9ca376b1064e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8475416936be400297fbd1d1ff2d0a45"}},"metadata":{}},{"name":"stdout","text":"[7]: Semantic Similarity: 0.88084, cache time: 0.5528759956359863, generate time: 18.273640632629395\nQ:  How to prevent Kidney Stones in Adults ?\nA:   Drinking plenty of water, maintaining a balanced diet, and managing underlying medical conditions can help prevent kidney stones in adults.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37084e222fb4461892abd1943aef21ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17ded5ddafb1418cab8078b4e4c7fe1d"}},"metadata":{}},{"name":"stdout","text":"[8]: Semantic Similarity: 0.78086, cache time: 0.570441722869873, generate time: 2.2402005195617676\nQ:  What to do for Kidney Stones in Adults ?\nA:   Treatment for kidney stones in adults typically involves a combination of the following:\n\n1. **Pain management**: Over-the-counter pain relievers like ibuprofen or acetaminophen to manage pain and discomfort.\n2. **Hydration**: Drinking plenty of water to help flush out the stone.\n3. **Medications**: In some cases, medications like alpha-blockers or pain relievers may be prescribed.\n4. **Surgery**: In severe cases, surgical removal of the stone (lithotripsy) or removal of the affected kidney (nephrectomy) may be necessary.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"522fc0e0c1d541b899fdb43efe099d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd3b12ad3ce40e1984364d7897cd164"}},"metadata":{}},{"name":"stdout","text":"[9]: Semantic Similarity: 0.73155, cache time: 0.5667226314544678, generate time: 11.008107900619507\n\nPrepare time: 7.623744964599609\nAverage Semantic Similarity: 0.6748782932758332\ncache time: 0.6763349771499634,\t generate time: 4.91129949092865\n\n\nInteractive Query Mode:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your query:  what is cancer?\n"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Generated Answer:\n what is cancer? cancer is a group of diseases characterized by the uncontrolled growth and spread of abnormal cells. these abnormal cells can invade and damage surrounding tissues and organs, and can also spread to other parts of the body through the bloodstream or lymphatic system.\ncancer can be caused by a variety of factors, including:\ngenetic mutations\nenvironmental exposures\ninfections\nradiation\ntobacco use\nobesity\nphysical inactivity\ncertain medications\ncancer can be classified into several types, including:\ncarcinomas\nsarcomas\nleukemias\nlymphomas\nmelanomas\nthere are many different types of cancer, and each type has its own unique characteristics and treatment options.\nsymptoms of cancer may include:\nunexplained weight loss\nfatigue\npain\nswelling or lumps\nbleeding or discharge\nabnormal cell growth\ncancer can be diagnosed through a variety of tests, including:\nbiopsy\nimaging tests\nblood tests\ngenetic testing\ncancer treatment options may include:\nsurgery\nradiation therapy\nchemotherapy\ntargeted therapy\nimmunotherapy\ncancer is a complex and multifaceted disease, and there is no single cause or cure. however, with advances in medical research and treatment, many types of cancer can be effectively treated and managed.\n**cancer statistics**\n\n* according to the american cancer society, there were over 1.9 million new cases of cancer diagnosed in the united states in\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"_uuid":"98b69f46-b8c5-40b7-9a24-aac544a7b44d","_cell_guid":"f145bd9b-8b0c-415a-8f56-5cc5fd5c95f0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}